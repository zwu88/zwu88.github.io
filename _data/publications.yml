# Publications data for automated CV generation
main:
  - title: "TANTE: Time-Adaptive Operator Learning via Neural Taylor Expansion"
    alt_title: "TANTE"
    paper_id: "5biMMmIAAAAJ:u5HHmVD_uO8C"
    authors: Zhikai Wu, Sifan Wang, Shiyang Zhang, Sizhuang He, Min Zhu, Anran Jiao, Lu Lu, and David van Dijk
    date: Oct 2025
    conference_short: In Review
    conference: In Review
    pdf: https://arxiv.org/pdf/2502.08574
    code: https://github.com/zwu88/TANTE
    bibtex: ./assets/bibs/tante.txt
    image: ./assets/img/tante.gif
    # poster: ./assets/posters/CaLMFlow_NYAS_Poster.pdf
    # blog: https://research.google/blog/teaching-machines-the-language-of-biology-scaling-large-language-models-for-next-generation-single-cell-analysis/
    notes: Preprint
    tags: ["Operator Learning", "PDEs", "Adaptive Step Size"]
    selected: true
    summary: "C2S-Scale scales this framework to 27 billion parameters trained on a billion-token multimodal corpus—achieving state-of-the-art predictive and generative performance for complex, multicellular analyses."
    full_abstract: "Operator learning for time-dependent partial differential equations (PDEs) has seen rapid progress in recent years, enabling efficient approximation of complex spatiotemporal dynamics. However, most existing methods rely on fixed time step sizes during rollout, which limits their ability to adapt to varying temporal complexity and often leads to error accumulation. Here, we propose the Time-Adaptive Transformer with Neural Taylor Expansion (TANTE), a novel operator-learning framework that produces continuous-time predictions with adaptive step sizes. TANTE predicts future states by performing a Taylor expansion at the current state, where neural networks learn both the higher-order temporal derivatives and the local radius of convergence. This allows the model to dynamically adjust its rollout based on the local behavior of the solution, thereby reducing cumulative error and improving computational efficiency. We demonstrate the effectiveness of TANTE across a wide range of PDE benchmarks, achieving superior accuracy and adaptability compared to fixed-step baselines, delivering accuracy gains of 60-80 % and speed-ups of 30-40 % at inference time. The code is publicly available at https://github.com/zwu88/TANTE for transparency and reproducibility."
  
  - title: "GeoFunFlow: Geometric Function Flow Matching for Inverse Operator Learning over Complex Geometries"
    alt_title: "GeoFunFlow"
    paper_id: "5biMMmIAAAAJ:9yKSN-GCB0IC"
    authors: Sifan Wang<sup>*</sup>, Zhikai Wu<sup>*</sup>, David van Dijk, and Lu Lu
    date: Sep 2025
    conference_short: In Review
    conference: In Review
    pdf: https://arxiv.org/pdf/2509.24117
    # code: https://github.com/MrGiovanni/ContinualLearning
    bibtex: ./assets/bibs/caddi.txt
    image: ./assets/img/caddi.png
    tags: ["Diffusion Models", "Causal Language Models", "Generative Modeling"]
    selected: true
    summary: "We introduce a novel approach to discrete diffusion models that conditions on the entire generative trajectory, thereby lifting the Markov constraint and allowing the model to revisit and improve past states. CaDDi treats standard causal language models as a special case and permits the direct reuse of pretrained LLM weights with no architectural changes."
    full_abstract: "Discrete diffusion models offer a flexible, controllable approach to structured sequence generation, yet they still lag behind causal language models in expressive power. A key limitation lies in their reliance on the Markovian assumption, which restricts each step to condition only on the current state, leading to potential uncorrectable error accumulation. In this paper, we introduce CaDDi, a discrete diffusion model that conditions on the entire generative trajectory, thereby lifting the Markov constraint and allowing the model to revisit and improve past states. By unifying sequential (causal) and temporal (diffusion) reasoning in a single non-Markovian transformer, CaDDi also treats standard causal language models as a special case and permits the direct reuse of pretrained LLM weights with no architectural changes. Empirically, CaDDi outperforms state-of-the-art discrete diffusion baselines on natural-language benchmarks, substantially narrowing the remaining gap to large autoregressive transformers." 

  - title: "TANTE: Time-Adaptive Operator Learning via Neural Taylor Expansion"
    paper_id: "5biMMmIAAAAJ:u5HHmVD_uO8C"
    authors: Zhikai Wu, Sifan Wang, Shiyang Zhang, <b><u>Sizhuang He</u></b>, Min Zhu, Anran Jiao, Lu Lu, and David van Dijk
    date: Jan 2025
    conference_short: In Review
    conference: In Review
    pdf: https://arxiv.org/pdf/2502.08574
    # code: https://github.com/MrGiovanni/ContinualLearning
    bibtex: ./assets/bibs/tante.txt
    image: ./assets/img/tante.png
    # poster: ./assets/posters/CaLMFlow_NYAS_Poster.pdf
    # notes: Accepted to AI4MATH Workshop at ICML 2025 as a poster
    tags: ["Neural Operators", "Operator Learning"]
    full_abstract: "Operator learning for time-dependent partial differential equations (PDEs) has seen rapid progress in recent years, enabling efficient approximation of complex spatiotemporal dynamics. However, most existing methods rely on fixed time step sizes during rollout, which limits their ability to adapt to varying temporal complexity and often leads to error accumulation. Here, we propose the Time-Adaptive Transformer with Neural Taylor Expansion (TANTE), a novel operator-learning framework that produces continuous-time predictions with adaptive step sizes. TANTE predicts future states by performing a Taylor expansion at the current state, where neural networks learn both the higher-order temporal derivatives and the local radius of convergence. This allows the model to dynamically adjust its rollout based on the local behavior of the solution, thereby reducing cumulative error and improving computational efficiency. We demonstrate the effectiveness of TANTE across a wide range of PDE benchmarks, achieving superior accuracy and adaptability compared to fixed-step baselines, delivering accuracy gains of 60–80% and speed-ups of 30–40% at inference time. The code is publicly available at https://github.com/zwu88/TANTE for transparency and reproducibility."
  
  - title: "COAST: Intelligent Time-Adaptive Neural Operators"
    paper_id: "5biMMmIAAAAJ:Tyk-4Ss8FVUC"
    authors: Zhikai Wu, Shiyang Zhang, <b><u>Sizhuang He</u></b>, Sifan Wang, Min Zhu, Anran Jiao, Lu Lu, and David van Dijk
    date: Jan 2025
    conference_short: AI4MATH
    conference: AI4MATH Workshop at ICML 2025 (Poster)
    pdf: https://arxiv.org/pdf/2502.08574
    # code: https://github.com/MrGiovanni/ContinualLearning
    bibtex: ./assets/bibs/coast.txt
    image: ./assets/img/coast.png
    # poster: ./assets/posters/CaLMFlow_NYAS_Poster.pdf
    # notes: Accepted to AI4MATH Workshop at ICML 2025 as a poster
    tags: ["Neural Operators", "Operator Learning"]
    full_abstract: "Operator learning for time-dependent partial differential equations (PDEs) has seen rapid progress in recent years, enabling efficient approximation of complex spatiotemporal dynamics. However, most existing methods rely on fixed time step sizes during rollout, which limits their ability to adapt to varying temporal complexity and often leads to error accumulation. To address this gap, we propose the Time-Adaptive Transformer with Neural Taylor Expansion (TANTE), a novel operator-learning framework that produces continuous-time predictions with adaptive step sizes. TANTE predicts future states by performing a Taylor expansion at the current state, where neural networks learn both the higher-order temporal derivatives and the local radius of convergence. This allows the model to dynamically adjust its rollout based on the local behavior of the solution, thereby reducing cumulative error and improving computational efficiency. We demonstrate the effectiveness of TANTE across a wide range of PDE benchmarks, achieving superior accuracy and adaptability compared to fixed-step baselines, delivering accuracy gains of 10-50% and speed‑ups of 30-80% at inference."

  - title: "CaLMFlow: Flow Matching using Causal Language Models"
    alt_title: "CaLMFlow"
    paper_id: "5biMMmIAAAAJ:d1gkVwhDpl0C"
    authors: <b><u>Sizhuang He<sup>*</sup></u></b>, Daniel Levine<sup>*</sup>, Ivan Vrkic, Marco Bressana, David Zhang, Syed Rizvi, Yangtian Zhang, Emanuele Zappala, and David van Dijk
    date: Oct 2024
    conference_short: ArXiv
    conference: arXiv
    pdf: https://arxiv.org/pdf/2410.05292
    # code: https://github.com/MrGiovanni/ContinualLearning
    bibtex: ./assets/bibs/calmflow.txt
    image: ./assets/img/CaLMFlow.png
    # poster: ./assets/posters/CaLMFlow_NYAS_Poster.pdf
    notes: Preprint
    tags: ["Flow Matching", "Causal Language Models", "Generative Modeling", "Integral Equations"]
    selected: true
    summary: "We present Volterra Flow Matching, a novel generative modeling framework that reformulates ODE-based flow matching frameworks with Volterra Integral Equations, hence avoiding a core challenge in ODE-based methods, known as stiffness. We show the connection between Volterra Integral Equations and causal transformers, the backbone of modern Large Language Models and hence demonstrates that causal language models can be naturally extended to generative modeling over continuous data domains through the lens of Volterra Flow Matching."
    full_abstract: "We introduce CaLMFlow, a novel framework that recasts flow matching as a Volterra integral equation (VIE) while leveraging causal language models (CLMs) for continuous data generation. Although integral equations have previously been studied for nonlocal operator learning, we are the first to apply them explicitly to flow matching. By discretizing both time and space, CaLMFlow transforms continuous trajectories into a sequence-based representation, allowing standard large language model architectures to capture long-range dependencies and flexibly incorporate textual prompts. In experiments on synthetic benchmarks and a single-cell perturbation response task, CaLMFlow demonstrates improved stability and scalability over ODE-based methods in high-dimensional regimes. These findings suggest that combining an integral-equation formulation with CLMs provides a promising, context-aware paradigm for generative modeling."

  - title: Intelligence at the Edge of Chaos
    alt_title: "Intelligence at the Edge of Chaos"
    paper_id: "5biMMmIAAAAJ:qjMakFHDy7sC"
    authors: Shiyang Zhang<sup>*</sup>, Aakash Patel<sup>*</sup>, Syed Rizvi, Nianchen Liu, <b><u>Sizhuang He</u></b>, Amin Karbasi, Emanuele Zappala, and David van Dijk
    date: Oct 2024
    conference_short: ICLR
    conference: ICLR 2025 (Poster)
    pdf: https://arxiv.org/pdf/2410.02536
    # code: https://github.com/MrGiovanni/ContinualLearning
    bibtex: ./assets/bibs/complexity.txt
    image: ./assets/img/complexity.png
    # notes: Accepted to ICLR 2025 as a poster
    tags: ["Large Language Models", "Complexity Theory", "Cellular Automata"]
    selected: true
    summary: "By training LLMs on elementary cellular automata rules of varying complexity, we pinpoint a 'sweet spot' of data complexity that maximizes downstream predictive and reasoning abilities. Our findings suggest that exposing models to appropriately complex patterns is key to unlocking emergent intelligence."
    full_abstract: "We explore the emergence of intelligent behavior in artificial systems by investigating how the complexity of rule-based systems influences the capabilities of models trained to predict these rules. Our study focuses on elementary cellular automata (ECA), simple yet powerful one-dimensional systems that generate behaviors ranging from trivial to highly complex. By training distinct Large Language Models (LLMs) on different ECAs, we evaluated the relationship between the complexity of the data generated by the rules and the models' ability to learn effective general representations, as reflected in their performance on downstream tasks. Our findings reveal that models trained on more complex data exhibit greater predictive ability, as demonstrated by their performance on reasoning and chess move prediction tasks. Both uniform and periodic systems, and often also highly chaotic systems, resulted in poorer downstream performance, highlighting a sweet spot of complexity conducive to intelligence. We conjecture that intelligence arises from the ability to predict complexity and that creating intelligence may require only exposure to complexity."

  - title: "Operator Learning Meets Numerical Analysis: Improving Neural Networks through Iterative Methods"
    paper_id: "5biMMmIAAAAJ:2osOgNQ5qMEC"
    authors: Emanuele Zappala, Daniel Levine, <b><u>Sizhuang He</u></b>, Syed Rizvi, Sacha L&eacute;vy, and David van Dijk
    date: Oct 2023
    conference_short: ArXiv
    conference: arXiv
    pdf: https://arxiv.org/pdf/2310.01618
    # code: https://github.com/MrGiovanni/ContinualLearning
    bibtex: ./assets/bibs/iterative_methods.txt
    image: ./assets/img/iterative_methods.png
    notes: Preprint
    tags: ["Numerical Analysis", "Operator Learning", "Integral Equations"]
    full_abstract: "Deep neural networks, despite their success in numerous applications, often function without established theoretical foundations. In this paper, we bridge this gap by drawing parallels between deep learning and classical numerical analysis. By framing neural networks as operators with fixed points representing desired solutions, we develop a theoretical framework grounded in iterative methods for operator equations. Under defined conditions, we present convergence proofs based on fixed point theory. We demonstrate that popular architectures, such as diffusion models and AlphaFold, inherently employ iterative operator learning. Empirical assessments highlight that performing iterations through network operators improves performance. We also introduce an iterative graph neural network, PIGN, that further demonstrates benefits of iterations. Our work aims to enhance the understanding of deep learning by merging insights from numerical analysis, potentially guiding the design of future networks with clearer theoretical underpinnings and improved performance."